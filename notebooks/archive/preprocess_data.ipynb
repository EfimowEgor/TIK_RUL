{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read -> Fill empty cells -> save cleaned\n",
    "#                          -> Apply transforms -> save preprocessed\n",
    "def fill_empty(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Fill empty cells with values from previous step.\n",
    "    \"\"\"\n",
    "    data = data.ffill()\n",
    "    return data\n",
    "\n",
    "# По сути это обёртка препроцессора, мне нужно разбить на функции, из которых состоит считываение данных\n",
    "def transform_header(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    data: Датафрейм, считанный из файла конфигуратора\n",
    "    \"\"\"\n",
    "\n",
    "    data = pd.concat([pd.DataFrame([data.columns], columns=data.columns), data], \n",
    "                     axis=0).reset_index(drop=True)\n",
    "    # Build header\n",
    "    date_column = pd.to_datetime(data.iloc[:, 0], errors='coerce', format='%d.%m.%Y %H:%M:%S').dropna().reset_index(drop=True)\n",
    "\n",
    "    array = data.iloc[0:3, 1::2].to_numpy().astype(str)\n",
    "\n",
    "    cols = []\n",
    "\n",
    "    for i in range(array.shape[1]):\n",
    "        cols.append(array[0, i] + ' ' + array[1, i] + ' ' + array[2, i])\n",
    "\n",
    "    cols = np.array(cols)\n",
    "\n",
    "    # Cut bad lines\n",
    "    delta = data.shape[0] - date_column.shape[0]\n",
    "    signal_values = data.iloc[delta:, 1::2].reset_index(drop=True)\n",
    "    signal_values = signal_values.apply(lambda x: \n",
    "                                        pd.to_numeric(\n",
    "                                            x.str.replace(',','.'),\n",
    "                                            errors='coerce')\n",
    "                                        )\n",
    "\n",
    "    cols = np.append(['date'], cols)\n",
    "    signal_values = pd.DataFrame(pd.concat([date_column, signal_values], axis=1).values, columns=cols)\n",
    "\n",
    "    return signal_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Component:\n",
    "    def __init__(self, \n",
    "                 data: np.ndarray,\n",
    "                 direction: str,\n",
    "                 idx: 'str' ) -> None:\n",
    "        self.direction = direction\n",
    "        self.data = data\n",
    "        self.idx = idx\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'data: {self.data}, direction: {self.direction}, idx: {self.idx}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(names: list[str]) -> dict[str, list[str]]:\n",
    "    name_groups = dict()\n",
    "    # format of names[i]: name acronym number metric name, join last 2 (or just drop)\n",
    "    splitted_names = [elem.split() for elem in names]\n",
    "    for elem in splitted_names:\n",
    "        acronym, direction, idx = elem[1][:-1], elem[1][-1], elem[2]\n",
    "        if acronym not in name_groups:\n",
    "            name_groups[acronym] = [(direction, idx)]\n",
    "        else:\n",
    "            name_groups[acronym].append((direction, idx))\n",
    "    return name_groups\n",
    "\n",
    "def group(splitted_data: dict[str, list[str]], \n",
    "          data: pd.DataFrame):\n",
    "    last_char = set()\n",
    "    for key in splitted_data:\n",
    "        l = len(splitted_data[key])\n",
    "        last_char.add(key[-1])\n",
    "        for values in range(l):\n",
    "            for column in data.columns.to_list():\n",
    "                if (key + splitted_data[key][values][0] in column) and (splitted_data[key][values][1] in column):\n",
    "                    splitted_data[key].insert(len(splitted_data[key]), data[column].to_numpy())\n",
    "                    \n",
    "    grouped = {k:{} for k in last_char}\n",
    "\n",
    "    for char in last_char:\n",
    "        for key in splitted_data:\n",
    "            if key[-1] == char:\n",
    "                grouped[char].update({key:splitted_data[key]})\n",
    "\n",
    "    return grouped   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/month_csv_acceleration.csv', skiprows=8, sep=';')\n",
    "df = transform_header(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join key and values[0] -> if key + values[0] in columns and values[1] in columns\n",
    "# Iterate over column names and compare everything\n",
    "# If have found -> get series\n",
    "df = fill_empty(df)\n",
    "dataset = split(df.columns.to_list()[1:])\n",
    "\n",
    "group(dataset, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get('ПЗД')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
