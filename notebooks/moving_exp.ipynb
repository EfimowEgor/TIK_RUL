{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import logging\n",
    "\n",
    "from DataLoader import (\n",
    "    config,\n",
    "    loader\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from scipy.interpolate import (\n",
    "    UnivariateSpline,\n",
    "    CubicSpline\n",
    ")\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    mean_absolute_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(signals: pd.DataFrame, floor: str='30min', method='max'):\n",
    "    \"\"\"\n",
    "    floor: https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases\n",
    "    method: Определяет каким образом сжимается ряд. Принимает значения 'max' - максимум интервала, 'mean' - среднее значение интервала, 'mixed' - E(x) + max()\n",
    "    \"\"\"\n",
    "    match method:\n",
    "        case 'max':\n",
    "            return signals.groupby(signals.date.dt.floor(floor)).max().drop('date', axis=1)\n",
    "        case 'mean':\n",
    "            return signals.groupby(signals.date.dt.floor(floor)).mean().drop('date', axis=1)\n",
    "        case 'mixed': \n",
    "            pass\n",
    "            # convolve, how to optimize params? perceptron?\n",
    "        case _:\n",
    "            raise ValueError(f'Unknown method: {method}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/raw/'\n",
    "\n",
    "files = os.listdir(data_path)\n",
    "\n",
    "# make a dict, key - file_name_last part\n",
    "dta = dict()\n",
    "datasets = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(data_path, file), skiprows=config.COUNT_SKIP, sep=';')\n",
    "    df = loader.fill_empty(loader.transform_header(df))\n",
    "    # Compress signal\n",
    "    compressed = compress(df, floor='10min', method='mean')\n",
    "    datasets.append(compressed)\n",
    "\n",
    "min_length = min(df.shape[0] for df in datasets)\n",
    "min_index = set(datasets[0].index)\n",
    "for df in datasets[1:]:\n",
    "    min_index.intersection_update(df.index)\n",
    "min_index = list(min_index)\n",
    "\n",
    "for i, df in enumerate(datasets):\n",
    "    datasets[i] = df.loc[min_index]\n",
    "\n",
    "# Проверка, что даты совпадают\n",
    "for i in range(len(files)):\n",
    "    for j in range(i + 1, len(files)):\n",
    "        assert np.setdiff1d(datasets[i].index, datasets[j].index).size == 0, f\"Intersection has shape {np.setdiff1d(datasets[i].index, datasets[j].index).shape}\"\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    datasets[i].sort_index(inplace=True)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "\n",
    "    splitted = loader.split(datasets[i].columns)\n",
    "    group = loader.group(splitted, datasets[i])\n",
    "\n",
    "    dta[file] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_moving_average(data, window):\n",
    "    weights = np.exp(np.linspace(-1., 0., window))\n",
    "    weights /= weights.sum()\n",
    "    ema = np.convolve(data, weights, mode='full')[:len(data)]\n",
    "    ema[:window] = ema[window]\n",
    "    return ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2time(rng: np.array):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 4, figsize=(14, 14))\n",
    "for i, file in enumerate(files):\n",
    "    j = 0 \n",
    "    for k in dta[file].keys():\n",
    "        for kk in dta[file][k].keys():\n",
    "            print(i, j, file, k, kk)\n",
    "            # print(dta[file][k][kk][len(dta[file][k][kk]) // 2:][0])\n",
    "            if len(dta[file][k][kk]) == 2:\n",
    "                sns.lineplot(exponential_moving_average(dta[file][k][kk][len(dta[file][k][kk]) // 2:][0], window=50), ax=ax[i][j])\n",
    "            else:\n",
    "                sns.lineplot(dta[file][k][kk][len(dta[file][k][kk]) // 2:], ax=ax[i][j])\n",
    "            # sns.kdeplot(dta[file][k][kk][len(dta[file][k][kk]) // 2:], ax=ax[i][j], color='green')\n",
    "            # sns.histplot(dta[file][k][kk][len(dta[file][k][kk]) // 2:], ax=ax[i][j])\n",
    "            # ax[i][j].set_xscale('log')\n",
    "            # ax[i][j].set_yscale('log')\n",
    "            ax[i][j].set_title(file + ' ' + k + ' ' + kk, fontsize=8)\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересные сигналы:\n",
    "1. Ускорение 10кГц ($y = -\\alpha e^{\\theta x}$)\n",
    "2. Эксцесс ($y = b + \\alpha e^{\\theta x}$)\n",
    "3. Скорость ($y = b + \\alpha e^{\\theta x}$)\n",
    "4. Перемещение ($y = -kx + b$) (возможно, не стоит брать, нужно бустрапить данные и смотреть статистики)\n",
    "\n",
    "Иначе говоря всё, кроме обычного ускорения\n",
    "\n",
    "Можно сделать бутстрап по этим сигналам, чтобы получить интервал среднего"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "объединение данных по компонентам (перенести в лоадер)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = defaultdict(list)\n",
    "for d in (dta.keys()):\n",
    "    for k_outer, v_outer in dta[d].items():\n",
    "        for k_inner, v_inner in v_outer.items():\n",
    "            # print(k_inner, v_inner)\n",
    "            dd[k_inner].append(v_inner)\n",
    "\n",
    "for key in dd.keys():\n",
    "    component_mat = np.array([])\n",
    "    for row in dd[key]:\n",
    "        data_row = np.array(row[len(row) // 2:])\n",
    "        if component_mat.size == 0:\n",
    "            component_mat = data_row\n",
    "        else:\n",
    "            component_mat = np.vstack([component_mat, data_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_exp_custom(x, f, t, b, e, s):\n",
    "    return f + t * e ** (b * x + e - (s ** 2) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['ППД']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = np.array(np.arange(1, len(dd['ППД'][0][1]) + 1))\n",
    "tmp = np.array([])\n",
    "for i in range(1, 5):\n",
    "    if tmp.size == 0:\n",
    "        tmp = dd['ППД'][i][1]\n",
    "    else:\n",
    "        tmp = np.vstack([tmp, dd['ППД'][i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед PCA нормализуем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tkeo_operator(data, k = 1):\n",
    "    \"\"\"\n",
    "    Teager-Kaiser Energy operator\n",
    "    \"\"\"\n",
    "    npnts = len(data[0])\n",
    "    nsignals = len(data)\n",
    "    filt_data = deepcopy(data)\n",
    "    for i in range(nsignals):\n",
    "        for n in range(k, npnts-k):\n",
    "            filt_data[i][n] = data[i][n]**2-data[i][n-1]*data[i][n+1]\n",
    "    return filt_data\n",
    "\n",
    "def normilize(signal: np.ndarray):\n",
    "    \"\"\"\n",
    "    MinMaxScaler + Teager-Kaiser Operator + MinMaxScaler\n",
    "    \"\"\"\n",
    "    # scalers = [MinMaxScaler, StandardScaler]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    signal = scaler.fit_transform(signal)\n",
    "    print(f'norm1 max: {signal.max()}, min: {signal.min()}')\n",
    "    signal = tkeo_operator(signal)\n",
    "    print(f'tkeo max: {signal.max()}, min: {signal.min()}')\n",
    "    signal = scaler.fit_transform(signal)\n",
    "    print(f'norm2 max: {signal.max()}, min: {signal.min()}')\n",
    "    return signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = normilize(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "compressed = pca.fit_transform(tmp.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(exponential_moving_average(abs(compressed[:, 1]), window=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интерполяция сигнала слайнами - апостериорная информация не применяется "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = []\n",
    "tail_len = 500\n",
    "x = np.arange(len(exponential_moving_average(abs(compressed[:, 1]), window=100)))\n",
    "y = exponential_moving_average(abs(compressed[:, 1]), window=100)\n",
    "for elem in x[::500]:\n",
    "    hist.append(np.arange(elem, elem + tail_len))\n",
    "\n",
    "for i in range(1, 7):\n",
    "    uni_spl = UnivariateSpline(np.arange(0, 500 * i), y[np.arange(0, 500 * i)])\n",
    "    sns.lineplot(x=np.arange(500 * i, len(x)), y=uni_spl(np.arange(500 * i, len(x))))\n",
    "    len(hist)\n",
    "\n",
    "sns.lineplot(y, label='true')\n",
    "plt.yscale('log')\n",
    "plt.title('Interpolate using univariate spline');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем функцию деградации.  \n",
    "Интерполяция сигнала экспоненциальной функцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_exp_weird(x, f, t, b, e, s):\n",
    "    return f + t * e ** (b * x + eps - (s ** 2) / 2)\n",
    "def fit_exp_classic(x, a, b, c):\n",
    "    return b + a * np.e ** (np.log(x) / c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.arange(1000)\n",
    "ydata = exponential_moving_average(abs(compressed[:, 1]), window=100)[:1000]\n",
    "popt, pcov = curve_fit(fit_exp_custom, xdata, ydata)\n",
    "popt2, pcov2 = curve_fit(fit_exp_classic, xdata, ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata_apriory = np.arange(1000, 3260)\n",
    "y_true = exponential_moving_average(abs(compressed[:, 1]), window=100)[xdata_apriory]\n",
    "y_pred = fit_exp_custom(xdata_apriory, *popt)\n",
    "y_pred2 = fit_exp_classic(xdata_apriory, *popt2)\n",
    "\n",
    "plt.plot(y_true, label='True')\n",
    "plt.plot(y_pred, label='Pred1')\n",
    "plt.plot(y_pred2, label='Pred2')\n",
    "plt.legend()\n",
    "plt.title('Non bayesian predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При предсказании на ~570 часов выход на уровень ошибки происходит за ~450 часов.  \n",
    "Отставание ~125 часов.  \n",
    "Забустрапить реализацию выборки  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 2260):\n",
    "    delta = abs(y_pred[i] - 0.3765174192095883)\n",
    "    if delta < .001:\n",
    "        print(f'Tick: {1000 + i}, dt = {3360 - (1000 + i)}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianRidge(max_iter=1000, tol=.001)\n",
    "model.fit(xdata.reshape(-1, 1), ydata.reshape(-1, 1))\n",
    "\n",
    "pred, std = model.predict(xdata_apriory.reshape(-1, 1), return_std=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.plot(y_true, label='True')\n",
    "plt.plot(pred, label='Pred')\n",
    "plt.scatter(xdata_apriory - 1000, y_true)\n",
    "plt.fill_between(xdata_apriory - 1000, pred-std, pred+std, color='pink', alpha=0.5, label='pred std')\n",
    "plt.legend();\n",
    "plt.title('Default $\\\\lambda$ and $\\\\alpha$ init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 2260):\n",
    "    delta = abs(pred[i] - 0.3765174192095883)\n",
    "    if delta < .001:\n",
    "        print(f'Tick: {1000 + i}, dt = {3360 - (1000 + i)}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Незначительное снижение отставания от реального времени. Это не совсем то, что нужно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***BAYESIAN INFERENCE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(\\theta|X) = \\frac{P(\\theta) P(X|\\theta)}{norm}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы \"знаем\" изначальное распределение параметров модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y(t) = \\phi + \\theta exp(\\beta t + \\epsilon - \\frac{\\sigma^2}{2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\phi$ - const  \n",
    "$\\theta$ - lognorm  \n",
    "\n",
    "$\\beta$ - norm (gaussian)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATM SKIP, CANNOT IMPLEMENT, HAVE NO IDEA ABOUT MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.stats import norm, lognorm\n",
    "\n",
    "# # Функция для вычисления функции y(t) с заданными параметрами\n",
    "# def y(t, phi, theta, beta):\n",
    "#     return phi + theta * np.exp(beta * t)\n",
    "\n",
    "# # Априорные распределения параметров\n",
    "# prior_theta_mean = 1.0\n",
    "# prior_theta_std = 0.5\n",
    "# prior_beta_mean = 0.0\n",
    "# prior_beta_std = 0.1\n",
    "\n",
    "# # Начальные значения параметров\n",
    "# phi = 0.0\n",
    "# theta = np.random.lognormal(prior_theta_mean, prior_theta_std)\n",
    "# beta = np.random.normal(prior_beta_mean, prior_beta_std)\n",
    "\n",
    "# # Временной ряд (первые 100 значений для начальной модели)\n",
    "# time_series = exponential_moving_average(abs(compressed[:, 1]), window=100)\n",
    "\n",
    "# # Построение начальной модели на первых 100 значениях временного ряда\n",
    "# for t, y_value in enumerate(time_series[:1500]):\n",
    "#     new_t = t + 1\n",
    "#     new_y = y_value\n",
    "    \n",
    "#     # Обновление апостериорных распределений\n",
    "#     posterior_theta_mean = (prior_theta_mean * prior_theta_std**2 + new_y * np.exp(-beta * new_t) * theta) / (prior_theta_std**2 + np.exp(-2 * beta * new_t))\n",
    "#     posterior_theta_std = np.sqrt((prior_theta_std**2 * np.exp(2 * beta * new_t)) / (prior_theta_std**2 + np.exp(2 * beta * new_t)))\n",
    "#     posterior_beta_mean = (prior_beta_mean * prior_beta_std**2 + (new_y - phi - theta * np.exp(-prior_beta_mean * new_t)) * new_t) / (prior_beta_std**2 + new_t**2)\n",
    "#     posterior_beta_std = np.sqrt(prior_beta_std**2 / (prior_beta_std**2 + new_t**2))\n",
    "\n",
    "#     # Генерация новых значений параметров из апостериорных распределений\n",
    "#     theta = np.random.lognormal(posterior_theta_mean, posterior_theta_std)\n",
    "#     beta = np.random.normal(posterior_beta_mean, posterior_beta_std)\n",
    "\n",
    "# # Создание массивов для отслеживания изменений параметров\n",
    "# theta_values = []\n",
    "# beta_values = []\n",
    "\n",
    "# # fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "# # После построения начальной модели, обновляем параметры с поступлением новых данных\n",
    "\n",
    "# hist = []\n",
    "\n",
    "# for t, y_value in enumerate(time_series, start=1500):\n",
    "#     new_t = t + 1\n",
    "#     new_y = y_value\n",
    "    \n",
    "#     # Обновление апостериорных распределений\n",
    "#     posterior_theta_mean = (prior_theta_mean * prior_theta_std**2 + new_y * np.exp(-beta * new_t) * theta) / (prior_theta_std**2 + np.exp(-2 * beta * new_t))\n",
    "#     posterior_theta_std = np.sqrt((prior_theta_std**2 * np.exp(2 * beta * new_t)) / (prior_theta_std**2 + np.exp(2 * beta * new_t)))\n",
    "#     posterior_beta_mean = (prior_beta_mean * prior_beta_std**2 + (new_y - phi - theta * np.exp(-prior_beta_mean * new_t)) * new_t) / (prior_beta_std**2 + new_t**2)\n",
    "#     posterior_beta_std = np.sqrt(prior_beta_std**2 / (prior_beta_std**2 + new_t**2))\n",
    "\n",
    "#     # Генерация новых значений параметров из апостериорных распределений\n",
    "#     theta = np.random.lognormal(posterior_theta_mean, posterior_theta_std)\n",
    "#     beta = np.random.normal(posterior_beta_mean, posterior_beta_std)\n",
    "\n",
    "#     # Добавление значений параметров в массивы\n",
    "#     theta_values.append(theta)\n",
    "#     beta_values.append(beta)\n",
    "\n",
    "#     # Пересчет функции y(t) с новыми параметрами\n",
    "#     new_y_value = y(new_t, phi, theta, beta)\n",
    "\n",
    "#     print(\"Time:\", new_t)\n",
    "#     print(\"Updated theta:\", theta)\n",
    "#     print(\"Updated beta:\", beta)\n",
    "#     print(\"New y value:\", new_y_value)\n",
    "\n",
    "#     hist.append(new_y_value)\n",
    "\n",
    "#     # Построение графиков плотности распределения параметров\n",
    "#     fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "#     # Плотность распределения параметра theta\n",
    "#     sns.kdeplot(theta_values, ax=axes[0])\n",
    "#     # axes[0].hist(theta_values, bins=50, density=True, alpha=0.6, color='b')\n",
    "#     axes[0].set_title('Density Plot of Parameter Theta')\n",
    "#     axes[0].set_xlabel('Theta')\n",
    "#     axes[0].set_ylabel('Density')\n",
    "\n",
    "#     # Плотность распределения параметра beta\n",
    "#     sns.kdeplot(beta_values, ax=axes[1])\n",
    "#     # axes[1].hist(beta_values, bins=50, density=True, alpha=0.6, color='r')\n",
    "#     axes[1].set_title('Density Plot of Parameter Beta')\n",
    "#     axes[1].set_xlabel('Beta')\n",
    "#     axes[1].set_ylabel('Density')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчёт числа аномалий (граница - параметр функции). Экспоненциальный закон снижения остаточного ресурса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 варианта:\n",
    "1. простое пересечение границы (в данных это была бы уставка)\n",
    "2. автоэнкодер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметрическая граница"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_anomalies(data, thresh):\n",
    "    \"\"\"\n",
    "    thresh: Максимальное допустимое значение параметра модели\n",
    "    \"\"\"\n",
    "    return np.cumsum(data > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = exponential_moving_average(abs(compressed[:, 1]), window=100)\n",
    "sns.lineplot(count_anomalies(time_series, time_series.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции нужно будет вынести в пакет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение данных каждые N минут\n",
    "# Проверка превышения порога\n",
    "# Если превышен: v_i = v_{i-1} + 1\n",
    "# Иначе v_i = v_{i-1} + 0 <=> v_i = v_{i-1}\n",
    "# Тоже фитить экспоненту?\n",
    "# Или как-то статистически подобрать граничный параметр\n",
    "\n",
    "xdata = np.arange(5)\n",
    "ydata = exponential_moving_average(count_anomalies(time_series, time_series.mean()), window=100)[:1]\n",
    "popt, pcov = curve_fit(fit_exp_custom, xdata, ydata)\n",
    "popt2, pcov2 = curve_fit(fit_exp_classic, xdata, ydata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata_apriory = np.arange(1500, 3260)\n",
    "y_true =  exponential_moving_average(count_anomalies(time_series, time_series.mean()), window=100)[xdata_apriory]\n",
    "y_pred = fit_exp_custom(xdata_apriory, *popt)\n",
    "y_pred2 = fit_exp_classic(xdata_apriory, *popt2)\n",
    "\n",
    "plt.plot(y_true, label='True')\n",
    "# plt.plot(y_pred, label='Pred1')\n",
    "plt.plot(y_pred2, label='Pred2')\n",
    "plt.legend()\n",
    "plt.title('Anomaly prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(logger, x, y, func, start=5, end=3260):\n",
    "    x_start = x[:start]\n",
    "    y_start = y[:start]\n",
    "    popt, pcov = curve_fit(func, x_start, y_start)\n",
    "\n",
    "    init_pred = func(x[start:], *popt)\n",
    "\n",
    "    logger.info('Started')\n",
    "\n",
    "    logger.info(f'\\nINIT LOSSES:\\nMSE={mean_squared_error(y[start:], init_pred)},\\nRMSE={mean_squared_error(y[start:], init_pred, squared=False)},\\nMAE={mean_absolute_error(y[start:], init_pred)}')\n",
    "    logger.info(f'INIT FUNC PARAMS: {popt}')\n",
    "\n",
    "    for i in range(start + 1, end - 600):\n",
    "        try:\n",
    "            inner_popt, _ = curve_fit(func, x[:i], y[:i])\n",
    "        except RuntimeError as RE:\n",
    "            logger.info(f'\\n{i} EPOCH LOSS:\\nCAN NOT SOLVE')\n",
    "            continue\n",
    "        pred = func(x[i:], *inner_popt)\n",
    "\n",
    "        # Определение запаздывания\n",
    "        tick = - 1\n",
    "\n",
    "        for j in range(0, xdata.shape[0] - 1):\n",
    "            delta = abs(fit_exp_weird(xdata[:3420], *popt)[j] - 1499.2230827999854)\n",
    "            if delta < 1:\n",
    "                tick = j\n",
    "                break\n",
    "\n",
    "        logger.info(f'\\n{i} EPOCH LOSS:\\nMSE={mean_squared_error(y[i:], pred)},\\nRMSE={mean_squared_error(y[i:], pred, squared=False)},\\nMAE={mean_absolute_error(y[i:], pred)}\\nRUL={3360 - tick, tick}')\n",
    "\n",
    "        popt = np.mean( np.array([popt,inner_popt]), axis=0)\n",
    "        logger.info(f'FUNC PARAMS: {popt}')\n",
    "    \n",
    "    return popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('logger_exp')\n",
    "logging.basicConfig(filename='train_anomaly.log', level=logging.INFO)\n",
    "\n",
    "xdata = np.arange(exponential_moving_average(count_anomalies(time_series, time_series.mean()), window=100).shape[0])\n",
    "params = train(logger, xdata, exponential_moving_average(count_anomalies(time_series, time_series.mean()), window=100), fit_exp_custom)\n",
    "\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(ydata)\n",
    "sns.lineplot(fit_exp_weird(xdata[:3420], *params))\n",
    "sns.lineplot(exponential_moving_average(count_anomalies(time_series, time_series.mean()), window=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_moving_average(count_anomalies(time_series, time_series.mean()), window=100)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_moving_average(count_anomalies(time_series, time_series.mean()), window=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 3500):\n",
    "    delta = abs(fit_exp_weird(xdata[:3420], *params)[i] - 1499.2230827999854)\n",
    "    if delta < .1:\n",
    "        print(f'Tick: {i}, dt = {3360 - i}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "54 Часа отставания.  \n",
    "Проблема - граница аномалий подобрана мной (просто среднее).  \n",
    "Параметр должен подбираться на месте в течение какого-то времени. При этом возможно следует подсчитывать аномалии с нескольких сигналов. В качестве порога могут выступать уставки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно добавить вычисление и пересчёт доверительного интервала (чтобы можно было говорить про уверенность предсказания)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
