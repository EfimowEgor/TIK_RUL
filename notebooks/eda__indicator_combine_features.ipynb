{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Final\n",
    "\n",
    "import mlflow\n",
    "import mlflow.entities\n",
    "import mlflow.data.pandas_dataset\n",
    "from mlflow.data.sources import (\n",
    "    LocalArtifactDatasetSource\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE \n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    StandardScaler\n",
    ")\n",
    "\n",
    "from DataLoader import (\n",
    "    loader,\n",
    "    config\n",
    ")\n",
    "\n",
    "from Processer import preprocesser\n",
    "\n",
    "import pickle\n",
    "import PIL\n",
    "\n",
    "import scripts.compress_datatypes as S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = os.getenv(\"TRACKING_USER\")\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = os.getenv(\"TRACKING_PSWD\")\n",
    "os.environ[\"MLFLOW_HTTP_REQUEST_TIMEOUT\"] = \"9000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME: str = \"COMBINE FEATURES, BUILD ITS\"\n",
    "mlflow.set_tracking_uri(f\"http://{os.getenv('ADRESS')}:{os.getenv('PORT')}\")\n",
    "CURRENT_EXPERIMENT: mlflow.entities.Experiment = mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATASET FROM MLFLOW SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.artifacts.download_artifacts(run_id=\"36d231c830034e888ad1e04dd67741d5\", artifact_path=\"\")\n",
    "SOURSE_URI: str = \"mlflow-artifacts:/516249343314470222/36d231c830034e888ad1e04dd67741d5/artifacts/artifacts/data/feature_dataset_full.csv\"\n",
    "DST_PATH: str = \"../data/processed/mixed\"\n",
    "mlflow.artifacts.download_artifacts(artifact_uri=SOURSE_URI, dst_path=DST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATASET AS PD DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataset = pd.read_csv(os.path.join(DST_PATH, \"feature_dataset_full.csv/feature_dataset_full.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAN:\n",
    "1. LOAD HISTORICAL FEATURES (RMSA, RMSA10, ETC...)\n",
    "2. SMOOTH SIGNALS (OPTONAL)\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(feature_dataset, ax=ax);\n",
    "plt.yscale(\"log\");\n",
    "plt.xticks(rotation=90);\n",
    "\n",
    "RUN_NAME = \"PCA_EXPAND_HISTORICAL\"\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    mlflow.log_figure(fig, \"artifacts/charts/boxes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "_ = scaler.fit_transform(feature_dataset)\n",
    "pca = PCA(n_components=2)\n",
    "pca4 = pca.fit_transform(_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.regplot(data=pca4, x=pca4[:, 0], y=pca4[:, 1], ax=ax);\n",
    "sns.scatterplot(x=pca4[:, 0], y=pca4[:, 1], hue=feature_dataset.index.to_list(), legend=False, ax=ax);\n",
    "\n",
    "with mlflow.start_run(run_id=mlflow.search_runs(filter_string=f\"run_name='{RUN_NAME}'\")[\"run_id\"][0]) as run:\n",
    "    mlflow.log_figure(fig, \"artifacts/charts/pca2_reg.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAN SEE 2 GROUPS => WANT FIND CHANGE POINT  \n",
    "BUT HOW TO CONNECT CHANGE POINT TO RUL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTORICAL DATA\n",
    "# ----------\n",
    "RMSA_PATH: str = \"../data/raw/historical/СКЗУ.csv\"\n",
    "RMSA10_PATH: str = \"../data/raw/historical/СКЗУ10.csv\"\n",
    "RMSA_GROWTH: str = \"../data/raw/historical/СКЗУ_РОСТ.csv\"\n",
    "RMSA_AMP: str = \"../data/raw/historical/СКЗУ_АМПЛИТУДА.csv\"\n",
    "RMSD_SPAN: str = \"../data/raw/historical/СКЗП_РАЗМАХ.csv\"\n",
    "PK_FACTOR: str = \"../data/raw/historical/ПИК_ФАКТОР.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = [RMSA_PATH, RMSA10_PATH, RMSA_GROWTH, RMSA_AMP, RMSD_SPAN, PK_FACTOR]\n",
    "tmp = pd.DataFrame()\n",
    "for path in dataset_paths:\n",
    "    series_hist = pd.read_csv(path, skiprows=config.COUNT_SKIP, sep=';')\n",
    "    series_hist = loader.fill_empty(loader.transform_header(series_hist))\n",
    "    series_hist = preprocesser.compress(series_hist, floor='h', method=\"max\")\n",
    "\n",
    "    print(series_hist.shape)\n",
    "\n",
    "    if tmp.size == 0:\n",
    "        tmp = series_hist\n",
    "    else:\n",
    "        tmp = tmp.join(series_hist, on=tmp.index, how=\"inner\").drop(\"key_0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataset.index = pd.to_datetime(feature_dataset.index)\n",
    "date_series = pd.Series(feature_dataset.index)\n",
    "feature_dataset.index = date_series.dt.floor('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataset = feature_dataset.join(tmp, on=feature_dataset.index, how=\"inner\").drop(\"key_0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataset.to_csv(\"../data/processed/mixed/features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataset.columns = feature_dataset.columns.astype(str)\n",
    "\n",
    "dataset = mlflow.data.pandas_dataset.from_pandas(\n",
    "    feature_dataset, \n",
    "    name=\"HIST WITH STAT FEATURES\",\n",
    "    source=\"\"\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_id=mlflow.search_runs(filter_string=f\"run_name='{RUN_NAME}'\")[\"run_id\"][0]) as run:\n",
    "    mlflow.log_input(dataset, context=\"COMBINE STAT WITH HIST FEATURES\")\n",
    "    mlflow.log_artifact(\"../data/processed/mixed/features.csv\", \"artifacts/data\")\n",
    "    mlflow.log_table(feature_dataset, \"artifacts/data_json/features.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(13, figsize=(24,24))\n",
    "for i, col in enumerate(feature_dataset.columns):\n",
    "    sns.lineplot(feature_dataset[col], ax=ax[i])\n",
    "    ax[i].set_xticklabels(\"\")\n",
    "    ax[i].set_ylabel(col[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(feature_dataset)\n",
    "\n",
    "pca = PCA().fit(scaled_features)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "ax.axhline(0.95, c=\"green\")\n",
    "ax.axvspan(5, 6, alpha=.5, color=\"red\")\n",
    "ax.set_xlabel('number of components')\n",
    "ax.set_ylabel('cumulative explained variance')\n",
    "ax.set_title(\"Number of components vs explained variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=6)\n",
    "pca6 = pca.fit_transform(scaled_features)\n",
    "sns.pairplot(pd.DataFrame(pca6), corner=True, kind=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "_ = scaler.fit_transform(feature_dataset)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca2 = pca.fit_transform(_)\n",
    "\n",
    "sns.scatterplot(x=pca2[:, 0], y=pca2[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataset[\"dategroup\"] = np.where(feature_dataset.index < pd.Timestamp(\"12.01.2021\"), 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range1 = feature_dataset[feature_dataset.index < pd.Timestamp(\"12.01.2021\")]\n",
    "range2 = feature_dataset[(feature_dataset.index >= pd.Timestamp(\"12.01.2021\")) &\n",
    "                         (feature_dataset.index < pd.Timestamp(\"01.01.2022\"))]\n",
    "range3 = feature_dataset[(feature_dataset.index >= pd.Timestamp(\"01.01.2022\")) &\n",
    "                         (feature_dataset.index < pd.Timestamp(\"02.01.2022\"))]\n",
    "range4 = feature_dataset[feature_dataset.index >= pd.Timestamp(\"02.01.2022\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataset[\"dategroup\"].loc[range1.index] = 1\n",
    "feature_dataset[\"dategroup\"].loc[range2.index] = 2\n",
    "feature_dataset[\"dategroup\"].loc[range3.index] = 3\n",
    "feature_dataset[\"dategroup\"].loc[range4.index] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dategroup = feature_dataset[\"dategroup\"]\n",
    "feature_dataset.drop(\"dategroup\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "_ = scaler.fit_transform(feature_dataset)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca2 = pca.fit_transform(_)\n",
    "\n",
    "sns.scatterplot(x=pca2[:, 0], y=pca2[:, 1], hue=dategroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
