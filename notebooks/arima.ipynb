{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "import pmdarima as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(path: str, nskip: int = 0, sep: str = ';') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    path: Путь к csv с сигналами из конфигуратора  \n",
    "    nskip: Число строк в начале файла, которые нужно пропустить  \n",
    "    sep: Разделитель в csv файле\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, skiprows=nskip, sep=sep)\n",
    "    return df\n",
    "def preprocess_data(df: pd.DataFrame, accident_date: str = '') -> tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    df: Датафрейм, считанный из файла конфигуратора\n",
    "    accident_date: Дата аварии (либо интересующего места). Место обрезки данных. Если из конфигуратора сразу получено как нужно, то оставить None\n",
    "    \"\"\"\n",
    "    df = df.ffill()\n",
    "    # Получение столбца с датой и временем\n",
    "    new_row = pd.DataFrame([df.columns], columns=df.columns)\n",
    "    df = pd.concat([new_row, df], axis=0).reset_index(drop=True)\n",
    "\n",
    "    date_column = pd.to_datetime(df.iloc[:, 0], errors='coerce', format='%d.%m.%Y %H:%M:%S').dropna().reset_index(drop=True)\n",
    "\n",
    "    array = df.iloc[0:3, 1::2].to_numpy().astype(str)\n",
    "\n",
    "    print(array)\n",
    "\n",
    "    cols = []\n",
    "\n",
    "    for i in range(array.shape[1]):\n",
    "        cols.append(array[0, i] + ' ' + array[1, i] + ' ' + array[2, i])\n",
    "\n",
    "    cols = np.array(cols)\n",
    "\n",
    "    # print(cols)\n",
    "\n",
    "    delta = df.shape[0] - date_column.shape[0]\n",
    "    signal_values = df.iloc[delta:, 1::2].reset_index(drop=True)\n",
    "    signal_values = signal_values.apply(lambda x: x.str.replace(',','.'))\n",
    "    signal_values = signal_values.apply(lambda x: pd.to_numeric(x, errors='coerce')) \n",
    "\n",
    "    cols = np.append(['date'], cols)\n",
    "    signal_values = pd.DataFrame(pd.concat([date_column, signal_values], axis=1).values, columns=cols)\n",
    "\n",
    "    X = signal_values.drop('date', axis=1).apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    # print(signal_values.info())\n",
    "    y = signal_values['date']\n",
    "\n",
    "    # Обрезка данных, если задана дата поломки\n",
    "    # Иначе берём весь набор данных\n",
    "    if accident_date != '':\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def plot_lineplot(x: pd.Series, y: pd.Series, name: str, ax: Any, figsize = (1200, 1200)) -> None:\n",
    "    \"\"\"\n",
    "    x: Набор временных меток (временной ряд), либо последовательность 1..n (0..n-1), где n == len(y)\n",
    "    y: Значения в ith момент времени\n",
    "    name: Имя прямой\n",
    "    figsize: Размер графика\n",
    "    \"\"\"\n",
    "    # fig, ax = plt.subplots(figsize=(figsize[0] // 100, figsize[1] // 100))\n",
    "    sns.lineplot(x=x.index, y=y, ax=ax)\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('')\n",
    "    ax.set_title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data('../data/raw/month_csv_acceleration.csv', nskip=8, sep=';')\n",
    "df, date = preprocess_data(df)\n",
    "# plot_lineplot(date, df[df.columns[0]], df.columns[0], interactive=True)\n",
    "tmp = pd.concat([df, date], axis=1)\n",
    "tmp = tmp.replace([np.inf, -np.inf], np.nan)\n",
    "tmp = tmp.dropna().reset_index(drop=True)\n",
    "df = tmp.drop('date', axis=1)\n",
    "date = tmp['date']\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i in range(df.shape[1]):\n",
    "    plot_lineplot(date, (df[df.columns[i]]), ax=ax, name='')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "def poly(x, a, b):\n",
    "    return (1 / a) * np.exp(-b * x)\n",
    "\n",
    "# date, 1 / df[df.columns[i]]\n",
    "x = np.arange(0, date.shape[0])\n",
    "y = 1 / (df[df.columns[0]] + 1)\n",
    "y2 = df[df.columns[0]]\n",
    "\n",
    "popt, pcov = curve_fit(poly, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.plot(poly(x, *popt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), \n",
    "            mask=np.triu(np.ones_like(df.corr(), dtype=bool)) | (np.abs(df.corr()) < .5),\n",
    "            annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Декомпозиция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series((1 / df[df.columns[0]]).values, index=np.arange(0, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = pd.Series((1 / df[df.columns[0]]).values, index=np.arange(0, len(df)))\n",
    "# plt.rc(\"figure\", figsize=(16,8))\n",
    "# res = seasonal_decompose(q, model='additive', period = int(len(df) / 2))\n",
    "# res.plot().suptitle('Additive Decompose')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(res.seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace = go.Scatter(x=np.arange(len(date)), y=res.seasonal, mode='lines', name='Seasonality')\n",
    "# layout = go.Layout(title='Seasonality', xaxis=dict(title='Date'), yaxis=dict(), width=1200, height=1200)\n",
    "# figure = go.Figure(data=[trace], layout=layout)\n",
    "# del trace, layout\n",
    "# figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6045 - 881"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6045 - 881\n",
    "# trace = go.Scatter(x=date, y=res.seasonal, mode='lines', name='Seasonality')\n",
    "# layout = go.Layout(title='Seasonality', xaxis=dict(title='Date'), yaxis=dict(), width=1200, height=1200)\n",
    "# figure = go.Figure(data=[trace], layout=layout)\n",
    "# del trace, layout\n",
    "# figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Component:\n",
    "    def __init__(self, \n",
    "                 data: np.ndarray,\n",
    "                 direction: str,\n",
    "                 idx: 'str' ) -> None:\n",
    "        self.direction = direction\n",
    "        self.data = data\n",
    "        self.idx = idx\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'data: {self.data}, direction: {self.direction}, idx: {self.idx}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(names: list[str]) -> dict[str, list[str]]:\n",
    "    name_groups = dict()\n",
    "    # format of names[i]: name acronym number metric name, join last 2\n",
    "    splitted_names = [elem.split() for elem in names]\n",
    "    for elem in splitted_names:\n",
    "        acronym, direction, idx = elem[1][:-1], elem[1][-1], elem[2]\n",
    "        if acronym not in name_groups:\n",
    "            name_groups[acronym] = [(direction, idx)]\n",
    "        else:\n",
    "            name_groups[acronym].append((direction, idx))\n",
    "    return name_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = split(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем по компонентам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_collection: dict[str, list[Component]] = dict()\n",
    "for k in dataset:\n",
    "    for c in df.columns:\n",
    "        if (k[-1] not in component_collection):\n",
    "            if k in c:\n",
    "                component_collection[k[-1]] = [Component(df[c].to_numpy(), dataset[k][0][0], dataset[k][0][1])]\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            if k in c:\n",
    "                component_collection[k[-1]].append(Component(df[c].to_numpy(), dataset[k][0][0], dataset[k][0][1]))\n",
    "            else:\n",
    "                continue\n",
    "component_collection    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если имя совпадает (кроме последней буквы), то направление и индекс багаются. Нужно пофиксить. Дальше можно будет обучать модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist().pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_collection: dict[str, list[Component]] = dict()\n",
    "for k in dataset:\n",
    "    for i, c in enumerate(df.columns):\n",
    "        if (k[-1] not in component_collection):\n",
    "            if k in c:\n",
    "                component_collection[k[-1]] = [Component(df[c].to_numpy(), dataset[k][0][0], dataset[k][0][1])]\n",
    "                print(i, c)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            if k in c:\n",
    "                component_collection[k[-1]].append(Component(df[c].to_numpy(), dataset[k][0][0], dataset[k][0][1]))\n",
    "                print(i, c)\n",
    "            else:\n",
    "                continue\n",
    "component_collection    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_arr = np.array([])\n",
    "n_arr = np.array([])\n",
    "for elem in component_collection['Д']:\n",
    "    if d_arr.size == 0:\n",
    "        d_arr = np.array(elem.data)\n",
    "    else:\n",
    "        d_arr = np.vstack([d_arr, np.array(elem.data)])\n",
    "d_arr = d_arr.T\n",
    "\n",
    "for elem in component_collection['Н']:\n",
    "    if n_arr.size == 0:\n",
    "        n_arr = np.array(elem.data)\n",
    "    else:\n",
    "        n_arr = np.vstack([n_arr, np.array(elem.data)])\n",
    "n_arr = n_arr.T\n",
    "\n",
    "d_arr, n_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0, d_arr[:, 0].shape[0], 1)\n",
    "y = d_arr[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos =  int(0.8 * X.shape[0])\n",
    "X_train, X_test, y_train, y_test =  X[:pos], X[pos:], y[:pos], y[pos:]\n",
    "# Check if split correct\n",
    "assert ((X_train.shape[0] + X_test.shape[0]) == X.shape[0])\n",
    "assert ((y_train.shape[0] + y_test.shape[0]) == y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n",
    "\n",
    "\n",
    "# # Original Series\n",
    "# fig, axes = plt.subplots(1, 3, sharex=True)\n",
    "# # axes[0, 0].plot(y_train); axes[0, 0].set_title('Original Series')\n",
    "# plot_acf(y_train, ax=axes[0], lags=np.arange(0, 20, 1))\n",
    "\n",
    "# # 1st Differencing\n",
    "# # axes[1, 0].plot(pd.Series(y_train).diff()); axes[1, 0].set_title('1st Order Differencing')\n",
    "# plot_acf(pd.Series(y_train).diff().dropna(), ax=axes[1], lags=np.arange(0, 20, 1))\n",
    "\n",
    "# # 2nd Differencing\n",
    "# # axes[2, 0].plot(pd.Series(X_train).diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\n",
    "# plot_acf(pd.Series(y_train).diff().diff().dropna(), ax=axes[2], lags=np.arange(0, 20, 1))\n",
    "\n",
    "# plt.show()\n",
    "# # model = ARIMA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n",
    "\n",
    "\n",
    "# # Original Series\n",
    "# fig, axes = plt.subplots(1, 3, sharex=True)\n",
    "# # axes[0, 0].plot(y_train); axes[0, 0].set_title('Original Series')\n",
    "# plot_pacf(y_train, ax=axes[0], lags=np.arange(0, 20, 1))\n",
    "\n",
    "# # 1st Differencing\n",
    "# # axes[1, 0].plot(pd.Series(y_train).diff()); axes[1, 0].set_title('1st Order Differencing')\n",
    "# plot_pacf(pd.Series(y_train).diff().dropna(), ax=axes[1], lags=np.arange(0, 20, 1))\n",
    "\n",
    "# # 2nd Differencing\n",
    "# # axes[2, 0].plot(pd.Series(X_train).diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\n",
    "# plot_pacf(pd.Series(y_train).diff().diff().dropna(), ax=axes[2], lags=np.arange(0, 20, 1))\n",
    "\n",
    "# plt.show()\n",
    "# # model = ARIMA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adfuller(y, maxlag=50, regression='ct', autolag=None))\n",
    "print(kpss(y, regression='ct', nlags=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P должно быть равно не больше, чем 4\n",
    "D = 2 (или 1)\n",
    "Q = 3 (либо 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start fit ARIMA')\n",
    "model = ARIMA(y_train, order=(2, 1, 2)) # damped holt`s exponential smoothing\n",
    "r = model.fit()\n",
    "print(r.summary())\n",
    "# print(r.forecast(25, alpha=0.05))\n",
    "\n",
    "print('Start forecast')\n",
    "fc = r.forecast(1000)\n",
    "\n",
    "fc_series = pd.Series(fc, index=np.arange(pos, pos + 1000, 1))\n",
    "\n",
    "print('Start plotting')\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "# plt.plot(np.arange(pos - 50000, pos, 1), y_train[-50000:], label='training')\n",
    "plt.plot(np.arange(pos, pos + 1000, 1), y_test[:1000], label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='lower left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIT AUTO.ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_decompose(y_train[-1000:], model='add',  period = int(len(y_train[-1000:])/ 2)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pm.auto_arima(y_train[-1000:], start_p=1, start_q=1, max_p=5, max_q=5,\n",
    "                      start_P=0, \n",
    "                      trace=True,\n",
    "                      n_jobs=8,  # depends on cpu\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True,\n",
    "                      seasonal=True,\n",
    "                      m=500,\n",
    "                      stepwise=False, random=True, random_state=42,\n",
    "                      n_fits=50)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(n_periods=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train[-100:])\n",
    "plt.axhline(y_train[-100:].mean(), c='r')\n",
    "plt.plot(np.arange(100, 200, 1), pred, label='actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [y for y in y_train[-50:]]\n",
    "predictions =[]\n",
    "\n",
    "for i in range(1, len(y_test[:10000])):\n",
    "  # print(i)\n",
    "  model = ARIMA(history[-50:], order=(0, 2, 2)) # holt's smoothing\n",
    "  model = model.fit()\n",
    "\n",
    "  yhat = model.forecast()[0]\n",
    "  predictions.append(yhat)\n",
    "\n",
    "  obs = y_test[i]\n",
    "  history.append(obs)\n",
    "\n",
    "# f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 4))\n",
    "# sns.lineplot(y_test, ax=ax)\n",
    "# sns.lineplot(predictions, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(y_test[:10000])\n",
    "sns.lineplot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "sns.lineplot(predictions, ax=ax[0])\n",
    "sns.lineplot(y_test[:10000], ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_moving_average(data, window):\n",
    "    weights = np.exp(np.linspace(-1., 0., window))\n",
    "    weights /= weights.sum()\n",
    "    ema = np.convolve(data, weights, mode='full')[:len(data)]\n",
    "    ema[:window] = ema[window]\n",
    "    return ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10\n",
    "# ema = exponential_moving_average(y, window)[:100000]\n",
    "ema = y[:720000]\n",
    "z = np.polyfit(np.arange(0, ema.shape[0]), ema, 1)\n",
    "trend = np.poly1d(z)(np.arange(0, ema.shape[0]))\n",
    "plt.plot(ema)\n",
    "plt.plot(trend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit Holt Winters (aka ARIMA(0, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start fit ARIMA')\n",
    "model = ARIMA(y_train, order=(3, 1, 2)) # damped holt`s exponential smoothing\n",
    "r = model.fit()\n",
    "print(r.summary())\n",
    "# print(r.forecast(25, alpha=0.05))\n",
    "\n",
    "print('Start forecast')\n",
    "fc = r.forecast(100000)\n",
    "\n",
    "fc_series = pd.Series(fc, index=np.arange(pos, pos + 100000, 1))\n",
    "\n",
    "print('Start plotting')\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "# plt.plot(np.arange(pos - 50000, pos, 1), y_train[-50000:], label='training')\n",
    "plt.plot(np.arange(pos, pos + 100000, 1), y_test[:100000], label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='lower left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
